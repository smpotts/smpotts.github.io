---
layout: page
title: Resume
cover-img: /assets/img/fiesta5.jpg
---

### Summary
I am a passionate, creative, and curious Senior Software Engineer seeking to use and expand skill sets in backend engineering, data, and cloud technologies. A growth focused self-learner ready to adapt to any toolset, an evangelist for quality, a champion of collaboration.

### Technical Skills Summary
***SQL***: Redshift, MySQL, Postgres, SQL Server  
***Software Engineering/ ETL***: dbt, Ruby on Rails, Java, Python, Terraform, Kafka, Looker, Google Analytics  
***Operating Systems***: Mac, Linux  
***Cloud Services***: Amazon Web Services, Google BigQuery  
***Project Management***: Git, Notion, Kanban, Asana, Agile methodologies, JIRA, Confluence  

### Education
#### University of Denver  
Bachelor of Science in Computer Science  
Minors: Mathematics, Spanish  
June 2016  

### Certifications
AWS Certified Solutions Architect Associate - April 2023  
AWS Certified Cloud Practitioner - February 2023  
Certified Scrum Master - May 2022  

### Professional Experience
#### eSpark Learning 
Software Engineer III   /    *August 2021 – Present*   
* Demonstrated strong leadership and project management skills as Certified Scrum Master by leading scrum rituals, creating team processes, and curating a technical documentation space in Notion
    * Met with stakeholders to determine priorities, scope, and deliverables for each sprint
* Refined ways to use data to improve product decision making and company wide data usability
    * Helped define and reimplement key company metrics
    * Leveraged analytics data in Redshift to build internal and external dashboards in Metabase to help Customer and Sales teams demonstrate product efficacy
    * Planned and executed a major clean up and restructuring of the internal company Metabase
* Built new avenues to provide accurate, clean data to the core Ruby on Rails application for better in-product decision making
    * Refactored the core Ruby on Rails application to run more efficiently after integrating data from the Salesforce Data API
    * Leveraged the Redshift Data API with Ruby on Rails to solve data duplication issues and inconsistent metric calculations
* Created new dbt models for analytics after analyzing data coming from the Ruby on Rails monolith and Kinesis Firehose streams
* Developed API integrations with heavily relied upon 3rd party data sources (Calendly, Salesforce, Intercom) in order to capture accurate data in the Ruby on Rails application
* Enhanced and supported critical AWS cloud infrastructure used by the core applications, company website, and engineering teams
    * Setup new AWS infrastructure, contributed to CI/CD setup, and created Github actions for new engineering projects
    * Migrated existing AWS infrastructure into Terraform so it could be maintained under source control
    * Wrote Lambda functions in Python to automate CloudFront cache invalidations, data pipelines, and repeated processes
* Unblocked a crucial upgrade to Rails 7 for the core Rails application by migrating from the Paperclip gem to the ActiveStorage gem
* Helped phase out retired products by refactoring and removing deprecated Ruby code

#### Nasdaq 
Software Engineer II   /   *July 2018 – August 2021*
* Worked on a new project which formulated order audit trail regulatory reports for clients and submitted them to FINRA on their behalf
    * Streamed drops of their daily trading activity using Java, Spring Boot, Kafka, Kubernetes, and various AWS services, and pieced together a cohesive timeline showing the lifecycle of the linked orders
* Developed and delivered risk management reports to clients regarding complex trading strategies in use, risk exposure levels, market inconsistencies, and billing tiers calculations using Microsoft SQL Server
    * Helped maintain a cluster of 12 Windows servers both physical and virtual, to process the data and deliver roughly 300 daily reports
    * Migrated the project’s version control from VSS to git
* Constructed and maintained a new data warehouse in Postgres with a REST API interface to analyze team report delivery metrics and ensure SLA accuracy
* Leveraged an open source project called Poli to implement an internal dashboard and analytics tool to create ad-hoc reports, visualize reporting data, and minimize manual processes
    * Configured JDBC connections to Postgres, MySQL, and SQL Server reporting databases and wrote queries to serve data to the dashboard components

#### Craftsy (an NBCUniversal Company) 
Data Warehouse Developer   /   *October 2017 – July 2018*  
* Enhanced the scope of the data warehouse project by pipelining data from additional sources and refining the architecture to meet the needs of the business analysts and data consumers
    * Configured the data visualization tool, Looker, to retrieve data from the data warehouse to make available to populate dashboards, analyze business segments, and enable users to create self-service reports
* Created a marketing forecast to calculate 30-day rolling averages to forecast important business metrics, marketing costs, and revenue for different marketing channels
* Developed API connections for several marketing channels (YouTube, Facebook, Pinterest and more) to gather ad engagement metrics and attribute costs to marketing actions
* Assembled a new development environment and created development standards for the data warehouse project
    * Put the project in version control in git and created a workflow of task management in JIRA
    * Set up a version-controlled password management tool for the project using Python SOPS

#### Nasdaq
Software Engineer I   /   *June 2016 – September 2017*  
* Created a workflow engine for a new equities dark pool using Java and Spring, and ingested data into separate secure client accounts in Redshift per regulatory requirements
* Helped launch a new Business Intelligence project and created a unified platform for five options and three equities exchanges to deliver BI reports
    * Established a snowflake data model and developed ETL with Pentaho Data Integration
    * Documented and maintained source to target data mappings and collaborated with various business units on their reporting needs

#### Nasdaq
Software Engineering Intern   /   *June 2015 – June 2016*
* Assisted senior engineers in developing the Nasdaq Data Warehouse application written in Java and Spring
    * Pipelined raw data from the trading system into AWS under heavy regulatory requirements
    * Enforced data quality and data integrity while ingesting millions of records per day
    * Archived the data from Redshift into long term storage in Amazon S3 and Glacier

#### Forsythe Technologies
Software Engineering Intern   /   *May 2014 – February 2015*
* Developed a Java program to translate lists of each client’s business processes, and their dependencies, into dynamic BPMN diagrams embedded in a webpage using JavaScript and AngularJS
* Documented the development process using several software modeling techniques such as UML diagrams, class diagrams, sequence diagrams, and activity diagrams